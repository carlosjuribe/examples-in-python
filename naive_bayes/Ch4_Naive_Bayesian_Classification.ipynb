{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- [ ] Create table of contents mimicking [this](https://sebastianraschka.com/Articles/2014_ipython_internal_links.html)\n",
    "- [ ] Export utils functions, like play_audio and tada, to outer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31m### Functions and data useful for any kind of project\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0mplay_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound_file\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\" Plays outloud sound_file \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msound_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0mtada\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtada_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../../../tada.mp3\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mplay_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtada_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0mtada2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtada_path2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./tada.mp3\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mplay_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtada_path2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pycat ../../../personal_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Audio\n",
    "\n",
    "def play_audio(sound_file: str):\n",
    "    \"\"\" Plays outloud sound_file \"\"\"\n",
    "    display(Audio(url=sound_file, autoplay=True))\n",
    "    \n",
    "    \n",
    "def tada():\n",
    "    tada_path = \"../../../tada.mp3\"\n",
    "    play_audio(tada_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "\n",
    "<!-- [Building the Spam Filter](Building the Spam Filter) <br> -->\n",
    "\n",
    "<a href='#Tokenization'>4) Tokenization and Context</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a Spam Filter using Bayes Theorem\n",
    "---\n",
    "We want to build a Spam filter that classifies e-mails in two groups: **fraud** and **no fraud** sales.\n",
    "Our e-mails can have features like \"has_promotional_codes\" or \"has_giftcards\" that we could use to make better judgments about if an e-mail contains a fraudulent sale or not.\n",
    "But how do we feed this information to a spam classifier?\n",
    "\n",
    "We can convert this information to proportions (i.e., probabilities) and use Bayes theorem to train a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Naive Bayes Classifier** is a supervised and *probabilistic* learning model. It works well for problems where:\n",
    "* Data for which the inputs are independent from one another\n",
    "* Data where the probability of any attribute is greater than zero, always"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conidtional Probabilities\n",
    "\n",
    "\\begin{equation}\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "\\end{equation}\n",
    "\n",
    "The **intersection function $ \\cap $** (informally called *cap* due to its shape) can also be thought of as the Boolean operator **AND** applied on sets. In Python it looks like:\n",
    "```python\n",
    "a = [1, 2, 3]; b = [1, 4, 5]\n",
    "\n",
    "set(a) & set(b)  # => {1}\n",
    "set(a).intersection(set(b)) == set(a) & set(b)  # => True\n",
    "```\n",
    "\n",
    "The **union function $\\cup$** (informally called *cup* due to its shape) can be thought of as the **OR** operator:\n",
    "```python\n",
    "set(a) | set(b)  # => {1, 2, 3, 4, 5}\n",
    "set(a).union(set(b)) == set(a) | set(b)  # => True\n",
    "```\n",
    "We can see the idea of conditional probability in Python like this:\n",
    "```python\n",
    "A, B = set(a), set(b)\n",
    "total_cases = len(A) + len(B)\n",
    "\n",
    "p_A_cap_B = len(A & B) / total_cases  # => 0.16, probability of intersection happening\n",
    "p_B = len(B) / total_cases  # => 0.5, probability of B happening\n",
    "\n",
    "# So, according to the conditional probability formula above\n",
    "p_A_given_B = p_A_cap_B / p_B  # => 0.333\n",
    "\n",
    "# which always satisfies the following inequality:\n",
    "p_B > p_A_given_B > p_A_cap_B  # => True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Conditional Probability (*aka* Bayes Theorem)\n",
    "\n",
    "But what if we want to know the opposite case, that is, what if we want to know the probability of B, given A?.\n",
    "In that case, we can reason backwards and recalling that $ A \\cap B = B \\cap A $:\n",
    "\n",
    "From the conditional probability formula above, we know that\n",
    "$$ P(A \\cap B) = P(A|B)P(B) $$\n",
    "\n",
    "So, starting again with the conditional probability and substituting the expression for $ P(B \\cap A) $ we have\n",
    "$$ P(B|A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{P(A|B)P(B)}{P(A)} $$\n",
    "\n",
    "which is known as **Bayes Theorem**. We state it again for simplicity:\n",
    "\n",
    "$$ P(B|A) = \\frac{P(A|B)P(B)}{P(A)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesian Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Chain Rule\n",
    "\n",
    "Using the joint probability, the previous result transforms into the chain rule.<br>\n",
    "Joint probabilities are the probability that all the events will happen at the same time. The generic form is:\n",
    "$$\n",
    "P(A_1, A_2, ..., A_n) = P(A_1)P(A_2|A_1)P(A_3 | A_1, A_2)···P(A_n | A_1, A_2, ..., A_{n-1})\n",
    "$$\n",
    "\n",
    "\n",
    "##### Navieté in Bayesian Reasoning\n",
    "\n",
    "Sometimes, when we strictly apply Bayes Theorem, we can run into trouble because we need to use values of probabilities that we cannot compute. For example, $ P(Promos | Giftcards, Fraud) $ can be very hard, or even impossible, to get.\n",
    "But we still need to get going. We solve this problem by doing a rather big assumption (the *Navieté assumption*) to help us proceed in cases where some information is too difficult or impossible to get. The **Navieté** assumption consists in **considering only the individual effect that each event (Giftcard, Promos, ...) has in the event we want to predict**, in our case, fraud sales e-mails.\n",
    "\n",
    "$$ \n",
    "\\text{what we want to know} = P(Fraud | Giftcard, Promos) = \\frac{P(Giftcard, Promos, Fraud)}{P(Giftcard, Promos)}\n",
    "$$\n",
    "\n",
    "$ P(Giftcard, Promos) $ is easy to obtain, and thanks to the Navieté assumption (no interdependence of things like *having promo codes* and *having giftcards* (which really is unrealistic) we can simplify the numerator to an expression that we can really work with, given our data. So our numerator becomes:\n",
    "\n",
    "$$ \n",
    "P(Giftcard, Promos, Fraud) = P(Fraud)P(Giftcard|Fraud)P(Promos|Fraud)\n",
    "$$\n",
    "\n",
    "and our final model being:\n",
    "\n",
    "$$\n",
    "P(Fraud | Giftcard, Promos) = \\frac{P(Fraud)P(Giftcard | Fraud)P(Promos | Fraud)}{P(Giftcard, Promos)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if something like $ P(Promos | Fraud) = 0 $? That could happen due to new information, or not considering enough data. In that case, since probabilites here are just divisions of counts, we use what's called a **pseudocount**, which is just the real count of a class plus 1. In that way, we ensure that every computed probability will be always greater than zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Spam Filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the coding design for this exercise:\n",
    "\n",
    "<img src=\"images/coding_design.jpeg\" style=\"width: 190px;\">\n",
    "\n",
    "Each `Email` object takes an `.eml` text file that then tokenizes into something that the `SpamTrainer` can utilize. <br>\n",
    "When testing, we will focus on the tradeoff between false positives and false negatives, since in this scenario, a **false positive** (filtering out an e-mail as SPAM when it is not) **could be very harmful for a business**. Thus, we will try to **minimize the false positive rate**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data source\n",
    "\n",
    "* **CSDMC2010 SPAM corpus** <br>\n",
    "This data set has 4,327 total messages, of which 2,949 are ham and 1,378 are spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Test-Driven Development\n",
    "----\n",
    "\n",
    "Let's first define the class that will appropriately parse the e-mails in the `.eml` text files. But since we will use **TDD**, before we actually implement the class, we must first build the class(es) that will put to the test each desired functionality for that class. In this manner, after we have developed the class, we have a judge (the test) that objectively tells us whether or not the class does what we want them to do. <br>\n",
    "The steps are the following:\n",
    "\n",
    "##### 1 ) Write the test class for the desired class\n",
    "If you want to build a class *ClassX*, first build a class *TestClassX* inside which you use *ClassX* as if it were already implemented, according to the functionalities (methods and attributes) that you envision for it.\n",
    "\n",
    "Represent what you want the class to do inside the test class. Any method that starts with `test_` will be treated as a test to run. You can write auxiliary methods that do not follow this name pattern. <br>\n",
    "Also, each test class needs a method called `setUp`, whose job is to \"set it all up\" for the proper generation of the actual result and the expected result, so that they can be compared.\n",
    "\n",
    "```python\n",
    "class TestClassX(unittest.TestCase):\n",
    "    def setUp(self, ...):\n",
    "        # read/prepare data as ClassX would expected to be\n",
    "        \n",
    "    def test_functionality_1(self):\n",
    "        classX_instance = ClassX()\n",
    "        result = classX_instance.method_func1()  # method_func1 does not exist yet as this point\n",
    "        expected = function_that_does_the_right_thing()  # or a hardcoded \"true answer\"\n",
    "        self.assertEqual(result, expected)\n",
    "```\n",
    "##### 2) Implement the method that will do the functionality \n",
    "```python\n",
    "class ClassX(object):\n",
    "    def method_func1(self):\n",
    "        result_to_be_compared_with_expected_in_test = # do stuff\n",
    "        return result_to_be_compared_with_expected_in_test\n",
    "```\n",
    "\n",
    "##### 3) Run the test and see whether it passes.\n",
    "Recommended to store or the test classes in the same file for later automation  # TODO: How exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test # 1: `EmailObject`\n",
    "\n",
    "We want `EmailObject` to just parse the **subject** and the **body** of each email. So we'll have a method for each. <br>\n",
    "\n",
    "1) We begin by creating a class test targeted at the functionality of reading **plain text** e-mails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPlaintextEmailObject(unittest.TestCase):\n",
    "    \"\"\" Assumes there is a class EmailObject imported \"\"\"\n",
    "    \n",
    "    CRLF = \"\\r\\n\\r\\n\"  # carriage return and line feed.\n",
    "                       # Separates headers in our .eml files\n",
    "    \n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Loads example file against which the unit tests will be performed, and instantiates the \n",
    "        Email class on this file for later tests.\n",
    "        \"\"\"\n",
    "        self.plain_file = './tests/fixtures/plain.eml'\n",
    "        with open(self.plain_file, 'rb') as plaintext:\n",
    "            self.text = plaintext.read().decode('utf-8')  # text needed for the expected part of tests\n",
    "            plaintext.seek(0)  # point to start, so EmailObject can read it\n",
    "            # instantiate the to-be-tested class\n",
    "            self.plain_email = EmailObject(plaintext)  # expects binary files, not strings\n",
    "        \n",
    "    def test_parse_plain_body(self):\n",
    "        \"\"\" Check if body of email is extracted properly \"\"\"\n",
    "        body_expected = self.CRLF.join(self.text.split(self.CRLF)[1:])  # split on CRLF, take all except first one\n",
    "        body_actual = self.plain_email.body()  # behaviour of body method, not implemented yet\n",
    "        # compare method result with expected result\n",
    "        self.asserEqual(body_actual, body_expected)\n",
    "        \n",
    "    def test_parses_the_subject(self):\n",
    "        \"\"\" Check if subject of email is extracted properly \"\"\"\n",
    "        subject_expected = re.search(pattern=\"Subject: (.*)\", string=self.text).group(1)\n",
    "        subject_actual = self.plain_email.subject()\n",
    "        # compare\n",
    "        self.asserEqual(subject_actual, subject_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a test class, let's build the *first iteration* of its associated class that will make all the test pass.\n",
    "\n",
    "**NOTE**: Instead of relying purely on *Regular Expressions* for this text processing tasks, we will use Python's standard library `email` for this problem. Of course, this means our custom methods for `EmailObject` will depend on Python's `email` library functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "\n",
    "class EmailObject(object):\n",
    "    \"\"\"\n",
    "    Parses e-mails from .eml files.\n",
    "      ^\n",
    "     /|\\  1st Iteration\n",
    "    /_·_\\ \n",
    "    \"\"\"\n",
    "    def __init__(self, email_binary_file, category=None):\n",
    "        self.email_binary_file = email_binary_file\n",
    "        self.category = category\n",
    "        self.mail = email.message_from_binary_file(self.email_binary_file)  # TODO: returns what type?\n",
    "        \n",
    "    def subject(self):\n",
    "        return self.mail.get('Subject')\n",
    "        \n",
    "    def body(self):\n",
    "        return self.mail.get_payload(decode=True)  # TODO: type returned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Now we create a class test targeted at the functionality of reading **HTML** e-mails. For that, we need to capture only the `inner_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class TestHTMLEmail(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Assumes existence of an EmailObject.\n",
    "    Tests whether EmailOject properly reads HTML files\n",
    "    \"\"\"\n",
    "    CRLF = \"\\n\\n\"\n",
    "    def setUp(self):\n",
    "        # Prepare attributes to do the expected-vs-actual comparisons\n",
    "        with open('./tests/fixtures/html.eml', mode='rb') as html_file:\n",
    "            self.html = html_file.read().decode('utf-8')  # needed for the expected result part\n",
    "            html_file.seek(0)\n",
    "            # save object output to be tested below\n",
    "            self.html_email = EmailObject(html_file)  # accepts binary text files\n",
    "            \n",
    "    def test_parses_and_stores_inner_text_html(self):\n",
    "        body_temp = CRLF.join(self.html.split(CRLF)[1:])  # take all except first one\n",
    "        body_expected = BeautifulSoup(body_temp).text  # add 'html.parser' as 2nd argument if goes wrong\n",
    "        body_actual = self.html_email.body()  # tests method\n",
    "        self.assertEqual(body_actual, body_expected)\n",
    "        \n",
    "    def test_stores_subject(self):\n",
    "        subject_expected = re.search(pattern=\"Subject: (.*)\", string=self.html).group(1)\n",
    "        subject_actual = self.html_email.subject()  # tests method\n",
    "        self.assertEqual(subject_actual, subject_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we also need to detect the `content_type`, and not only the `inner_text`, we'll add a new feature to the body method in our `EmailObject` class that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailObject(object):\n",
    "    \"\"\"\n",
    "    Parses e-mails from .eml files.\n",
    "      ^\n",
    "     /|\\  2nd Iteration ==> Final version\n",
    "    /_·_\\ \n",
    "    \"\"\"\n",
    "    default_text_return = ''\n",
    "    \n",
    "    def __init__(self, email_binary_file, category=None):\n",
    "        self.email_binary_file = email_binary_file\n",
    "        self.category = category\n",
    "        self.mail = email.message_from_binary_file(self.email_binary_file)  # TODO: returns what type?\n",
    "        \n",
    "    def subject(self):\n",
    "        return self.mail.get('Subject')\n",
    "        \n",
    "    def body(self):\n",
    "        body_temp = self.mail.get_payload(decode=True)  # TODO: type returned?\n",
    "        content_type = self.mail.get_content_type()\n",
    "        # knowing content_type allows us to generalize the previous body method to HTML files\n",
    "        if content_type == 'text/html':\n",
    "            return BeautifulSoup(body_temp).text\n",
    "        elif content_type == 'text/plain':\n",
    "            return body_temp\n",
    "        else:\n",
    "            return self.default_text_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a working email parser, but we still have to deal with *tokenization*, or what to extract from the body and subject.\n",
    "\n",
    "### Tokenization and Context\n",
    "Because we are building a **Naive** Bayesian Classifier, we are *assuming* that each individual token is contributing independently to the *spamminess* of the e-mail.\n",
    "\n",
    "The goal of our tokenizer will be to extract words into a stream in order to keep a **low memory profile**.\n",
    "\n",
    "As always, the process is the following:\n",
    "\n",
    "1) Make a conceptual or functional desing of what the class will do <br>\n",
    "2) Make a class test that will test those functionalities <br>\n",
    "3) Implement the actual class that will succeed the tests\n",
    "4) Run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTokenizer(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Checks that tokenization is properly done\n",
    "    \"\"\"\n",
    "    def setUp(self):\n",
    "        self.string = \"quick brown fox\"\n",
    "        \n",
    "    def test_downcase(self):\n",
    "        expected = self.string.split()\n",
    "        actual = Tokenizer.tokenize(list(map(str.upper, expected)))\n",
    "        self.assertEqual(actual, expected)\n",
    "        \n",
    "    def test_ngram(self):\n",
    "        \"\"\"\n",
    "        Tests result of ngram for n = 2\n",
    "        \"\"\"\n",
    "        expected = [\n",
    "            [u'\\u0000', \"quick\"],\n",
    "            [\"quick\", \"brown\"],\n",
    "            [\"brown\", \"fox\"],  # TODO: Is this comma here right?\n",
    "        ]\n",
    "        actual = Tokenizer.ngram(self.string, 2)\n",
    "        self.assertEqual(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    \"\"\"\n",
    "    Tokenizes words of email\n",
    "    \"\"\" \n",
    "    NULL = u'\\u0000'\n",
    "    \n",
    "    @staticmethod  # decorator used for self-contained utility functions used only in current class\n",
    "    def tokenize(string):\n",
    "        return re.findall(pattern='\\w+', string=string.lower())\n",
    "        \n",
    "    @staticmethod\n",
    "    def ngram(string, n):\n",
    "        \"\"\" \n",
    "        Doc  # TODO\n",
    "        \"\"\"\n",
    "        tokens = Tokenizer.tokenize(string)\n",
    "        \n",
    "        ngrams = []\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            shift = (i - n) + 1\n",
    "            padding = max(-shift, 0)\n",
    "            first_idx = max(shift, 0)\n",
    "            last_idx = first_idx + n - padding\n",
    "            \n",
    "            ngrams.append(Tokenizer.pad(tokens[first_idx:last_idx], padding))\n",
    "        \n",
    "        return ngrams\n",
    "        \n",
    "    @staticmethod\n",
    "    def pad(tokens, padding):\n",
    "        \"\"\"\n",
    "        # TODO: Doc, and explain briefly what this does.\n",
    "        \"\"\"\n",
    "        padded_tokens = []\n",
    "        \n",
    "        for i in range(padding):\n",
    "            padded_tokens.append(Tokenizer.NULL)\n",
    "            \n",
    "        return padded_tokens + tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way of parsing and tokenizing e-mails, we can move on to build the **Bayesian** portion of our spam filter: the **`SpamTrainer`**.\n",
    "\n",
    "It will do 3 things: \n",
    "#### - Storing training data\n",
    " - Storing a set of all categories\n",
    " - Storing a *unique* word count for each category\n",
    " - Storing the totals for each category\n",
    " \n",
    "#### - Building a Bayesian Classifier\n",
    "<!--  - asdasd -->\n",
    "\n",
    "#### - Error minimization through cross-validation\n",
    "<!-- - asdasd -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Storing a set of all category names (ham, spam, scram):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSpamTrainer(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Tests whether .....  # TODO\n",
    "    \"\"\"\n",
    "    def setUp(self):\n",
    "        self.training = [  # List[List[key, value]]\n",
    "            ['spam', './tests/fixtures/plain.eml'],\n",
    "            ['ham', './tests/fixtures/small.eml'],\n",
    "            ['scram', './tests/fixtures/plain.eml']\n",
    "        ]\n",
    "        self.trainer = SpamTrainer(self.training)\n",
    "        with open('./tests/fixtures/plain.eml', 'rb') as file:\n",
    "            self.email = EmailObject(file)\n",
    "        \n",
    "    def test_multiple_categories(self):\n",
    "        \"\"\" Capture all category names from the e-mails \"\"\"\n",
    "        expected = set(k for k, _ in self.training)\n",
    "        actual = self.trainer.categories()\n",
    "        self.assertEqual(actual, expected)\n",
    "        \n",
    "    def test_counts_all_at_zero(self):\n",
    "        expected_count = 0\n",
    "        for cat in ['_all', 'spam', 'ham', 'scram']:\n",
    "            actual_count = self.trainer.total_for(cat)\n",
    "            self.assertEqual(expected_count, actual_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class SpamTrainer(object):\n",
    "    \"\"\"\n",
    "    Docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, training_files):\n",
    "        self.categories = set()\n",
    "        \n",
    "        for category, file in training_files:\n",
    "            self.categories.add(category)\n",
    "        \n",
    "        self.totals = defaultdict(float)\n",
    "        self.training = {categ: defaultdict(float)\n",
    "                         for categ in self.categories}\n",
    "        self.to_train = training_files\n",
    "        \n",
    "    def total_for(self, category):\n",
    "        \"\"\" Doc \"\"\"\n",
    "        return self.totals[category]\n",
    "        \n",
    "    def categories(self):\n",
    "        \"\"\" Doc \"\"\"\n",
    "        \n",
    "    def method1(self):\n",
    "        \"\"\" Doc \"\"\"\n",
    "        \n",
    "    def method1(self):\n",
    "        \"\"\" Doc \"\"\"\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try methods here before putting them in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailObject:\n",
    "    \"\"\" Parses incoming email messages \"\"\"\n",
    "    \n",
    "    CRLF = \"\\r\\n\\r\\n\"  # carriage return and line feed. Separates headers\n",
    "\n",
    "    def __init__(self, infile, category=None):\n",
    "        \"\"\" Initializes an Email with its filepath, label and data (i.e., text) \"\"\"\n",
    "        self.infile = infile\n",
    "        self.category = category\n",
    "        self.mail = email.message_from_binary_file(self.infile)\n",
    "    \n",
    "    def subject(self) -> str:\n",
    "        \"\"\" Extracts the subject of the email \"\"\"\n",
    "        return self.mail.get(\"Subject\")\n",
    "        \n",
    "    def body(self):\n",
    "        \"\"\" Extracts the body of the email \"\"\"\n",
    "        payload = self.mail.get_payload(decode=True)\n",
    "        content_type = self.mail.get_content_type()\n",
    "        if content_type == 'text/html':\n",
    "            return BeautifulSoup(payload).text\n",
    "        elif content_type == 'text/plain':\n",
    "            return payload\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Tokenization'></a>\n",
    "\n",
    "### Tokenization and Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Tokenization.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parse_plain_body(self=None):\n",
    "        \"\"\"\n",
    "        Doc\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [References](./references_ch4.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
